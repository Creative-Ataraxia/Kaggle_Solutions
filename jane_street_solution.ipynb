{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏆 Jane Street Real-Time Market Data Forecasting\n",
    "\n",
    "* Author: **Roll20** (*creative-ataraxia.com*)\n",
    "* Date: Jan 21st, 2025\n",
    "* Objective: Design a quantitative model to forecast a financial responder value from `107` features\n",
    "* Results: Placed at **8.77%** on the leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports and Ultilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports**\n",
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-Party Libraries**\n",
    "import catboost as cb\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin, clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import stats\n",
    "from tensorflow.keras import Input, Model, callbacks, layers, losses, models, optimizers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_evaluation import jane_street_inference_server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions\n",
    "\n",
    "* A set of utility functions for executing shell commands and creating folders. \n",
    "* These functions help automate various tasks during setup and deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shell_command(command: str, cwd: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Executes a shell command and prints the output in real-time.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Running command: {command}\")\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            cwd=cwd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            shell=True,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == '' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "        stderr = process.stderr.read()\n",
    "        if stderr:\n",
    "            print(\"Errors:\\n\", stderr)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def create_folder(path: str, rm: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Creates a folder, optionally removing it first if it exists.\n",
    "    \"\"\"\n",
    "    if rm and os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Polar Transformer\n",
    "\n",
    "A custom transformer using Polars to preprocess data by scaling features, filling missing values, and clipping time-related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarsTransformer:\n",
    "    \"\"\"\n",
    "    A custom transformer for preprocessing data using Polars.\n",
    "    \"\"\"\n",
    "    def __init__(self, features: list = None, fillnull: bool = True, scale: bool = True, clip_time: bool = True) -> None:\n",
    "        self.features = features\n",
    "        self.fillnull = fillnull\n",
    "        self.scale = scale\n",
    "        self.clip_time = clip_time\n",
    "        self.statistics_mean_std = None\n",
    "        self.statistics_min_max = None\n",
    "\n",
    "    def set_features(self, features: list) -> None:\n",
    "        self.features = features\n",
    "\n",
    "    def fit_transform(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        if self.scale:\n",
    "            self.statistics_mean_std = {\n",
    "                column: {\"mean\": df[column].mean(), \"std\": df[column].std()}\n",
    "                for column in self.features\n",
    "            }\n",
    "\n",
    "        if self.clip_time:\n",
    "            self.statistics_min_max = {\n",
    "                column: {\"min\": df[column].min(), \"max\": df[column].max()}\n",
    "                for column in [\"feature_time_id\"]\n",
    "            }\n",
    "\n",
    "        if self.fillnull:\n",
    "            df = df.with_columns([pl.col(column).fill_null(0.0) for column in self.features])\n",
    "\n",
    "        if self.scale:\n",
    "            df = df.with_columns([\n",
    "                ((pl.col(column) - self.statistics_mean_std[column][\"mean\"]) /\n",
    "                 self.statistics_mean_std[column][\"std\"])\n",
    "                for column in self.features\n",
    "            ])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(self, df: pl.DataFrame, refit: bool = False) -> pl.DataFrame:\n",
    "        if refit and self.clip_time:\n",
    "            self.statistics_min_max.update({\n",
    "                column: {\n",
    "                    \"min\": (self.statistics_min_max[column][\"min\"] if df[column].min() is None\n",
    "                            else min(df[column].min(), self.statistics_min_max[column][\"min\"])),\n",
    "                    \"max\": (self.statistics_min_max[column][\"max\"] if df[column].max() is None\n",
    "                            else max(df[column].max(), self.statistics_min_max[column][\"max\"]))\n",
    "                }\n",
    "                for column in [\"feature_time_id\"]\n",
    "            })\n",
    "\n",
    "        if self.clip_time:\n",
    "            df = df.with_columns([pl.col(column).clip(self.statistics_min_max[column][\"min\"],\n",
    "                                                         self.statistics_min_max[column][\"max\"])\n",
    "                                  for column in [\"feature_time_id\"]])\n",
    "\n",
    "        if self.fillnull:\n",
    "            df = df.with_columns([pl.col(column).fill_null(0.0) for column in self.features])\n",
    "\n",
    "        if self.scale:\n",
    "            df = df.with_columns([\n",
    "                ((pl.col(column) - self.statistics_mean_std[column][\"mean\"]) / self.statistics_mean_std[column][\"std\"])\n",
    "                for column in self.features\n",
    "            ])\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "* A weighted R² metric, both in NumPy and PyTorch, as matched to the competition’s evaluation metric. \n",
    "* A custom PyTorch loss (WeightedR2Loss) is also provided so that our models can optimize for this metric directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_weighted(y_true: np.array, y_pred: np.array, sample_weight: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Compute the weighted R² score.\n",
    "    \"\"\"\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (\n",
    "        np.average((y_true) ** 2, weights=sample_weight) + 1e-38\n",
    "    )\n",
    "    return r2\n",
    "\n",
    "def r2_weighted_torch(y_true: torch.Tensor, y_pred: torch.Tensor, sample_weight: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the weighted R² score using PyTorch tensors.\n",
    "    \"\"\"\n",
    "    numerator = torch.sum(sample_weight * (y_pred - y_true) ** 2)\n",
    "    denominator = torch.sum(sample_weight * (y_true) ** 2) + 1e-38\n",
    "    r2 = 1 - (numerator / denominator)\n",
    "    return r2\n",
    "\n",
    "class WeightedR2Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch loss function for weighted R².\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon: float = 1e-38) -> None:\n",
    "        super(WeightedR2Loss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor, weights: torch.Tensor) -> torch.Tensor:\n",
    "        numerator = torch.sum(weights * (y_pred - y_true) ** 2)\n",
    "        denominator = torch.sum(weights * (y_true) ** 2) + 1e-38\n",
    "        loss = numerator / denominator\n",
    "        return loss\n",
    "\n",
    "def gs_metric(\n",
    "        true: np.ndarray,\n",
    "        pred: np.ndarray,\n",
    "        week: np.ndarray,\n",
    "        penalty: bool = False,\n",
    "        verbose: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Gini Stability metric.\n",
    "\n",
    "    See details here:\n",
    "    www.kaggle.com/competitions/home-credit-credit-risk-model-stability/overview/evaluation\n",
    "\n",
    "    Arguments:\n",
    "        true: array with labels\n",
    "        pred: array with predictions\n",
    "        week: array with week numbers\n",
    "        penalty: whether to apply a slope penalty\n",
    "        verbose: whether to print the results\n",
    "    Returns:\n",
    "        out: float\n",
    "    \"\"\"\n",
    "    # Sort by week\n",
    "    sorted_indices = np.argsort(week)\n",
    "    week_sorted = week[sorted_indices]\n",
    "    true_sorted = true[sorted_indices]\n",
    "    pred_sorted = pred[sorted_indices]\n",
    "\n",
    "    # Group by week\n",
    "    week_unique, week_index = np.unique(week_sorted, return_index=True)\n",
    "    grouped_true = np.split(true_sorted, week_index[1:])\n",
    "    grouped_pred = np.split(pred_sorted, week_index[1:])\n",
    "\n",
    "    # Calculate Gini for each week\n",
    "    ginis = np.zeros(len(week_unique))\n",
    "    for i, (true, pred) in enumerate(zip(grouped_true, grouped_pred)):\n",
    "        if len(np.unique(true)) == 1:\n",
    "            gini = 0.0\n",
    "        else:\n",
    "            gini = roc_auc_score(true, pred) * 2 - 1\n",
    "        ginis[i] = gini\n",
    "\n",
    "    # Calculate Gini Stability\n",
    "    slope, intercept, _, _, _ = stats.linregress(week_unique, ginis)\n",
    "    residuals = ginis - (slope*week_unique + intercept)\n",
    "    out = np.mean(ginis) - 0.5 * np.std(residuals)\n",
    "    if penalty:\n",
    "        out += 88.0 * min(0, slope)\n",
    "\n",
    "    # Print results\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Stability gini: {out:.3f}\"\n",
    "            f\", gini: {np.mean(ginis):.3f}\"\n",
    "            f\", slope: {88.0 * slope:.3f}\"\n",
    "            f\", std: {0.5 * np.std(residuals):.3f}\"\n",
    "        )\n",
    "        plt.plot(ginis)\n",
    "\n",
    "    out_dict = {\n",
    "        \"ginis\": ginis,\n",
    "        \"slope\": 88.0*slope,\n",
    "        \"std\": np.std(residuals)\n",
    "    }\n",
    "\n",
    "    return out, out_dict\n",
    "\n",
    "\n",
    "def r2_lgb(preds, train_data):\n",
    "    \"\"\"\n",
    "    Custom evaluation metric for LightGBM that computes a weighted R² score.\n",
    "    \n",
    "    Parameters:\n",
    "        preds (np.array): The predicted values.\n",
    "        train_data (lightgbm.Dataset): The training dataset containing labels and sample weights.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple with:\n",
    "            - A string with the name of the metric.\n",
    "            - The computed weighted R² score.\n",
    "            - A boolean indicating that higher values of R² are better.\n",
    "    \"\"\"\n",
    "    labels = train_data.get_label()\n",
    "    weights = train_data.get_weight()\n",
    "    if weights is None or len(weights) == 0:\n",
    "        weights = np.ones_like(labels)\n",
    "    \n",
    "    # Compute weighted mean squared error.\n",
    "    mse = np.average((preds - labels) ** 2, weights=weights)\n",
    "    \n",
    "    # Compute weighted mean of the squared true labels.\n",
    "    mean_y2 = np.average(labels ** 2, weights=weights) + 1e-38  # avoid division by zero\n",
    "    \n",
    "    # Compute weighted R².\n",
    "    r2 = 1 - mse / mean_y2\n",
    "    return 'r2', r2, True\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class R2Cbt:\n",
    "    def get_final_error(self, error, weight):\n",
    "        \"\"\"\n",
    "        Final error is computed as the ratio of the weighted error sum and the total weight.\n",
    "        \"\"\"\n",
    "        return error / weight if weight != 0 else error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        \"\"\"\n",
    "        For R², a higher value is better.\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        \"\"\"\n",
    "        Evaluate the weighted R² metric.\n",
    "        \n",
    "        Parameters:\n",
    "            approxes (list of list): A list (of length one) containing the predictions.\n",
    "            target (list): The true target values.\n",
    "            weight (list or None): Optional weights for each sample.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple (error_sum, weight_sum) where:\n",
    "                   - error_sum is computed as R² multiplied by the total weight.\n",
    "                   - weight_sum is the sum of weights.\n",
    "        \"\"\"\n",
    "        # CatBoost passes approxes as a list (even for single-output regression)\n",
    "        preds = np.array(approxes[0])\n",
    "        target = np.array(target)\n",
    "        \n",
    "        if weight is None or len(weight) == 0:\n",
    "            weight = np.ones_like(target)\n",
    "        else:\n",
    "            weight = np.array(weight)\n",
    "        \n",
    "        # Compute the weighted mean squared error.\n",
    "        mse = np.average((preds - target) ** 2, weights=weight)\n",
    "        # Compute weighted average of squared target values (with a small constant for numerical stability)\n",
    "        mean_y2 = np.average(target ** 2, weights=weight) + 1e-38\n",
    "        \n",
    "        # Compute weighted R²\n",
    "        r2 = 1 - mse / mean_y2\n",
    "        # Multiply by total weight to obtain the error sum (CatBoost expects a pair: error_sum and weight_sum)\n",
    "        error_sum = r2 * np.sum(weight)\n",
    "        weight_sum = np.sum(weight)\n",
    "        return error_sum, weight_sum\n",
    "\n",
    "    def get_description(self):\n",
    "        \"\"\"\n",
    "        Return a short string description of this metric.\n",
    "        \"\"\"\n",
    "        return \"R2\"\n",
    "\n",
    "def r2_cbt():\n",
    "    \"\"\"\n",
    "    Returns an instance of the custom CatBoost metric for weighted R².\n",
    "    \"\"\"\n",
    "    return R2Cbt()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configurations\n",
    "\n",
    "* Defines the environment-specific configurations, including file paths, API credentials, and global variables. \n",
    "* The configuration is set up to work both on Kaggle and on rented GPU environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global run name and model definitions\n",
    "RUN_NAME = \"full\"\n",
    "# The pretrained models chosen for inference (an ensemble of GRU models)\n",
    "MODEL_NAMES = [\"gru_2.0_700\", \"gru_2.1_700\", \"gru_2.2_700\", \"gru_3.0_700\", \"gru_3.1_700\", \"gru_3.2_700\"]\n",
    "WEIGHTS = np.array([1.0] * len(MODEL_NAMES)) / len(MODEL_NAMES)\n",
    "WEIGHTS = WEIGHTS / sum(WEIGHTS)\n",
    "N_ROLL = 1000\n",
    "TEST_SIZE = 200\n",
    "GAP = 0\n",
    "\n",
    "print(\"_\".join(MODEL_NAMES))\n",
    "print(WEIGHTS)\n",
    "\n",
    "# Prepare a small window of raw training data\n",
    "MAX_DATE = 1698\n",
    "COLS_ID = ['row_id', 'date_id', 'time_id', 'symbol_id', 'weight', 'is_scored']\n",
    "\n",
    "DEBUG = False\n",
    "CNT_DATES = 9\n",
    "CNT_DATES_NOT_SCORED = 4\n",
    "\n",
    "# Determine the execution environment based on environment variables\n",
    "KAGGLE = 'KAGGLE_URL_BASE' in os.environ\n",
    "VASTAI = not KAGGLE\n",
    "\n",
    "# Define base paths for different environments\n",
    "base_paths = {\n",
    "    \"VASTAI\": Path(\"/home/janestreet2024\"),\n",
    "    \"VASTAI_DATA\": Path(\"/workspace/kaggle/janestreet\"),\n",
    "    \"KAGGLE\": Path(\"/kaggle/input\"),\n",
    "}\n",
    "\n",
    "# Set paths based on the environment\n",
    "if VASTAI:  # rented GPU\n",
    "    base_path = base_paths[\"VASTAI\"]\n",
    "    base_path_data = base_paths[\"VASTAI_DATA\"]\n",
    "    PATH_DATA = base_path_data / \"data\"\n",
    "    PATH_MODELS = base_path_data / \"models\"\n",
    "    PATH_CODE = base_path / \"dist/janestreet-0.1-py3-none-any.whl\"\n",
    "elif KAGGLE:\n",
    "    base_path = base_paths[\"KAGGLE\"]\n",
    "    base_path_data = base_paths[\"KAGGLE\"]\n",
    "    PATH_DATA = base_path / \"jane-street-real-time-market-data-forecasting\"\n",
    "    PATH_MODELS = base_path / \"janestreet2025-models\"\n",
    "    PATH_CODE = base_path / \"janestreet2025-code/janestreet-0.1-py3-none-any.whl\"\n",
    "else:\n",
    "    raise ValueError(\"Unknown environment\")\n",
    "\n",
    "PATHS_DATA = {\n",
    "    \"train\": PATH_DATA / \"train\",\n",
    "    \"test\": PATH_DATA / \"test\",\n",
    "}\n",
    "\n",
    "# Set other configuration variables\n",
    "# Wandb\n",
    "WANDB_PROJECT = \"kaggle_janestreet\"\n",
    "\n",
    "# Kaggle\n",
    "KAGGLE_USERNAME = \"alexmason11\"\n",
    "\n",
    "# Random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Data column names\n",
    "COL_TARGET = \"responder_6\"\n",
    "COL_ID = \"symbol_id\"\n",
    "COL_DATE = \"date_id\"\n",
    "COL_TIME = \"time_id\"\n",
    "COL_WEIGHT = \"weight\"\n",
    "COL_WEEK = \"WEEK_NUM\"\n",
    "COLS_RESPONDERS = [f\"responder_{i}\" for i in range(11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Models\n",
    "\n",
    "* Ensemble Model Selection: Classes for creating ensemble models, selecting the best ensemble \n",
    "    * (using score, correlation, or forward selection methods), and aggregating predictions\n",
    "* Linear Models: Logistic regression\n",
    "* Neural Network Models: Custom neural network architectures, GRU for time series forecasting\n",
    "* Tree-based Models: Implementations of tree-based regressors such as LightGBM, CatBoost, XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, model, name, weight, update):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "        self.weight = weight\n",
    "        self.update = update\n",
    "\n",
    "class Ensemble:\n",
    "    \"\"\"LightGBM model.\"\"\"\n",
    "\n",
    "    def __init__(self, models) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the ensemble with a list of models.\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "\n",
    "    def fit(self, train_set, val_set, test_set=None, cat_cols: list = None, verbose: bool = False) -> None:\n",
    "        for model in self.models:\n",
    "            model.model.fit(train_set, val_set, test_set, cat_cols, verbose)\n",
    "        return self\n",
    "\n",
    "    def update(self, X, stocks, y, weights, dates, times, lr):\n",
    "        for model in self.models:\n",
    "            if model.update:\n",
    "                model.model.update(X, stocks, y, weights, dates, times, lr)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.array, *args, **kwargs) -> np.array:\n",
    "        \"\"\"\n",
    "        Predict probabilities.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        weights = []\n",
    "        for model in self.models:\n",
    "            preds_i = model.model.predict(X, *args, **kwargs)\n",
    "            preds.append(preds_i)\n",
    "            weights.append(model.weight)\n",
    "        preds = np.average(preds, axis=0, weights=weights / sum(weights))\n",
    "        return preds, None\n",
    "\n",
    "    def set_seed(self, seed: int) -> None:\n",
    "        \"\"\"\n",
    "        Set the seed for the ensemble (if applicable).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_params(self, deep: bool = True):\n",
    "        return {\n",
    "            \"models\": self.models,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "class EnsembleSelector:\n",
    "    \"\"\"Select models for the ensemble.\"\"\"\n",
    "\n",
    "    def __init__(self, params: dict, method: str = \"score\") -> None:\n",
    "        \"\"\"\n",
    "        Initialize the EnsembleSelector.\n",
    "\n",
    "        Arguments:\n",
    "            params: Dictionary with parameters for the ensemble selection.\n",
    "            method: Method for the ensemble selection: \"score\", \"corr\", \"forward\".\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.method = method\n",
    "        self.methods_map = {\n",
    "            \"score\": self.find_best_ensemble_score,\n",
    "            \"corr\": self.find_best_ensemble_corr,  # select models that maximize overall variance; don't add models with similar corr\n",
    "            \"forward\": self.find_best_ensemble_forward,\n",
    "        }\n",
    "        self.find_best_ensemble = self.methods_map[self.method]\n",
    "        self.selected_models = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Fit the ensemble selector.\n",
    "        \"\"\"\n",
    "        self.selected_models = self.find_best_ensemble(X, y)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Predict probabilities using the selected ensemble.\n",
    "        \"\"\"\n",
    "        preds = X[self.selected_models].mean(axis=1).values\n",
    "        preds = preds[:, np.newaxis]\n",
    "        preds = np.hstack((1 - preds, preds))\n",
    "        return preds\n",
    "\n",
    "    def find_best_ensemble_score(self, X: pd.DataFrame, y: pd.Series, corr_threshold: float = 0.95, max_n: int = 10) -> list:\n",
    "        \"\"\"\n",
    "        Find the best combination of models by iteratively adding models based on score and checking correlation.\n",
    "        \"\"\"\n",
    "        if \"corr_threshold\" in self.params:\n",
    "            corr_threshold = self.params[\"corr_threshold\"]\n",
    "        if \"max_n\" in self.params:\n",
    "            max_n = self.params[\"max_n\"]\n",
    "\n",
    "        cols = [i for i in X.columns if i not in [COL_ID, COL_DATE, COL_WEEK, COL_TARGET]]\n",
    "        scores = {}\n",
    "        for col in cols:\n",
    "            score, ginis = gs_metric(y.values, X[col].values, X[\"WEEK_NUM\"].values, verbose=False, penalty=False)\n",
    "            scores[col] = score\n",
    "\n",
    "        correlation_matrix = X[cols].corr()\n",
    "        selected_models = []\n",
    "        sorted_models = sorted(scores, key=scores.get, reverse=True)\n",
    "\n",
    "        i = 0\n",
    "        for model in sorted_models:\n",
    "            if all(correlation_matrix[model][selected] < corr_threshold for selected in selected_models):\n",
    "                selected_models.append(model)\n",
    "                ensemble_preds = X[selected_models].mean(axis=1).values\n",
    "                score, ginis = gs_metric(y.values, ensemble_preds, X[COL_WEEK].values, verbose=False, penalty=False)\n",
    "                print(f\"Model {i}. Adding {model}: individual score {scores[model]:.4f}, ensemble score {score:.4f}\")\n",
    "                i += 1\n",
    "                if len(selected_models) >= max_n:\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Skipping {model}: correlation is too high\")\n",
    "\n",
    "        return selected_models\n",
    "\n",
    "    def find_best_ensemble_forward(self, X: pd.DataFrame, y: pd.Series, max_n: int = 10, weights: bool = False):\n",
    "        \"\"\"\n",
    "        Find the best combination of models by iteratively adding models based on total score.\n",
    "        \"\"\"\n",
    "        if \"max_n\" in self.params:\n",
    "            max_n = self.params[\"max_n\"]\n",
    "        if \"weights\" in self.params:\n",
    "            weights = self.params[\"weights\"]\n",
    "        cols = [i for i in X.columns if i not in [COL_ID, COL_DATE, COL_WEEK, COL_TARGET]]\n",
    "        cols_best = []\n",
    "        score_best = 0.0\n",
    "        while True:\n",
    "            cols_left = [i for i in cols if i not in cols_best]\n",
    "            col_best = None\n",
    "            for col in tqdm(cols if weights else cols_left):\n",
    "                cols_tmp = cols_best.copy()\n",
    "                cols_tmp.append(col)\n",
    "                preds = X[cols_tmp].mean(axis=1).values\n",
    "                score, ginis = gs_metric(y.values, preds, X[\"WEEK_NUM\"].values, verbose=False, penalty=False)\n",
    "                if score > score_best:\n",
    "                    print(f\"{col}: {score:.4f}, {ginis['slope']:.4f}\")\n",
    "                    score_best = score\n",
    "                    col_best = col\n",
    "\n",
    "            if col_best is not None:\n",
    "                cols_best.append(col_best)\n",
    "            else:\n",
    "                print(cols_best)\n",
    "                break\n",
    "\n",
    "            if len(cols_best) >= max_n:\n",
    "                break\n",
    "\n",
    "        return cols_best\n",
    "\n",
    "    def find_best_ensemble_corr(self, X: pd.DataFrame, y, score_threshold: float = 0.65, max_n: int = 10):\n",
    "        \"\"\"\n",
    "        Find the best combination of models by iteratively adding models based on correlation and score threshold.\n",
    "        \"\"\"\n",
    "        if \"score_threshold\" in self.params:\n",
    "            score_threshold = self.params[\"score_threshold\"]\n",
    "        if \"max_n\" in self.params:\n",
    "            max_n = self.params[\"max_n\"]\n",
    "        cols = [i for i in X.columns if i not in [COL_ID, COL_DATE, COL_WEEK, COL_TARGET]]\n",
    "        scores = {}\n",
    "        for col in cols:\n",
    "            score, ginis = gs_metric(y.values, X[col].values, X[COL_WEEK].values, verbose=False, penalty=False)\n",
    "            if score >= score_threshold:\n",
    "                scores[col] = score\n",
    "\n",
    "        cols = list(scores.keys())\n",
    "        sorted_models = sorted(scores, key=scores.get, reverse=True)\n",
    "        selected_models = [sorted_models[0]]\n",
    "        print(f\"Model 0. Starting ensemble with {selected_models[0]}: score {scores[selected_models[0]]:.4f}\")\n",
    "\n",
    "        correlation_matrix = X[cols].corr()\n",
    "\n",
    "        i = 1\n",
    "        while len(selected_models) < max_n:\n",
    "            average_correlations = correlation_matrix[selected_models].mean(axis=1).drop(labels=selected_models, errors='ignore')\n",
    "            next_model = average_correlations.idxmin()\n",
    "            selected_models.append(next_model)\n",
    "\n",
    "            ensemble_preds = X[selected_models].mean(axis=1).values\n",
    "            score, ginis = gs_metric(y.values, ensemble_preds, X[COL_WEEK].values, verbose=False, penalty=False)\n",
    "            print(f\"Model {i}. Adding {next_model}: score {score:.4f}\")\n",
    "\n",
    "            if average_correlations.empty:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return selected_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Logistic Regression model.\"\"\"\n",
    "\n",
    "    def __init__(self, params: dict) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Logistic Regression model.\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.model = LogisticRegression(**params)\n",
    "        self.features = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Fit the model.\n",
    "        \"\"\"\n",
    "        self.model.fit(X, y)\n",
    "        self.classes_ = self.model.classes_\n",
    "        self.features = X.columns\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Predict probabilities.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def set_seed(self, seed: int) -> None:\n",
    "        \"\"\"\n",
    "        Set the seed for the model.\n",
    "        \"\"\"\n",
    "        self.params[\"random_state\"] = seed\n",
    "\n",
    "    def get_params(self, deep: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Get parameters for this estimator.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"params\": self.params,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        \"\"\"\n",
    "        Set the parameters of this estimator.\n",
    "        \"\"\"\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_collate_fn(batch: list) -> tuple[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Collate function for DataLoader to flatten the batch.\n",
    "    \"\"\"\n",
    "    X, resp, y, weights = zip(*batch)\n",
    "    X = torch.cat(X, dim=0)\n",
    "    resp = torch.cat(resp, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    weights = torch.cat(weights, dim=0)\n",
    "    return X, resp, y, weights\n",
    "\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping tensors, grouped by datetime.\"\"\"\n",
    "\n",
    "    T = 968\n",
    "\n",
    "    def __init__(self, X: np.array, resp: np.array, y: np.array, weights: np.array,\n",
    "                 symbols: np.array, dates: np.array, times: np.array, on_batch: bool = True):\n",
    "        self.on_batch = on_batch\n",
    "        self.num_features = X.shape[1]\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.resp = torch.tensor(resp, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.weights = torch.tensor(weights, dtype=torch.float32)\n",
    "        self.symbols = torch.tensor(symbols, dtype=torch.int64)\n",
    "        self.dates = torch.tensor(dates, dtype=torch.int64)\n",
    "        self.times = torch.tensor(times, dtype=torch.int64)\n",
    "\n",
    "        self.X = torch.nan_to_num(self.X, 0)\n",
    "\n",
    "        self.K = X.shape[1]\n",
    "\n",
    "        if not self.on_batch:\n",
    "            T = self.T\n",
    "            N, K = self.X.shape\n",
    "            sorted_indices = torch.argsort(self.times, stable=True)\n",
    "            sorted_indices = sorted_indices[torch.argsort(self.dates[sorted_indices], stable=True)]\n",
    "            sorted_indices = sorted_indices[torch.argsort(self.symbols[sorted_indices], stable=True)]\n",
    "            self.X = self.X[sorted_indices]\n",
    "            self.resp = self.resp[sorted_indices]\n",
    "            self.dates = self.dates[sorted_indices]\n",
    "            self.y = self.y[sorted_indices]\n",
    "            self.weights = self.weights[sorted_indices]\n",
    "            self.symbols = self.symbols[sorted_indices]\n",
    "            self.X = self.X.view(N // T, T, K)\n",
    "            self.resp = self.resp.view(N // T, T, self.resp.shape[-1])\n",
    "            self.dates = self.dates.view(N // T, T)[:, 0].squeeze()\n",
    "            self.y = self.y.view(N // T, T)\n",
    "            self.weights = self.weights.view(N // T, T)\n",
    "            self.symbols = self.symbols.view(N // T, T)\n",
    "\n",
    "        self.datetime_ids = self.dates\n",
    "        self.unique_datetimes, self.inverse_indices, self.counts = torch.unique(\n",
    "            self.datetime_ids, return_inverse=True, return_counts=True)\n",
    "        self.sorted_indices = torch.argsort(self.inverse_indices)\n",
    "        self.group_end_indices = torch.cumsum(self.counts, dim=0)\n",
    "        self.group_start_indices = torch.cat((torch.tensor([0]), self.group_end_indices[:-1]))\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor]:\n",
    "        start = self.group_start_indices[index]\n",
    "        end = self.group_end_indices[index]\n",
    "        index = self.sorted_indices[start:end]\n",
    "        X = self.X[index]\n",
    "        resp = self.resp[index]\n",
    "        y = self.y[index]\n",
    "        weights = self.weights[index]\n",
    "        if self.on_batch:\n",
    "            T = max(self.times[index]) + 1\n",
    "            X = X.reshape(T, -1, self.K).swapaxes(0, 1)\n",
    "            resp = resp.reshape(T, -1, resp.shape[1]).swapaxes(0, 1)\n",
    "            y = y.reshape(T, -1).swapaxes(0, 1)\n",
    "            weights = weights.reshape(T, -1).swapaxes(0, 1)\n",
    "        return X, resp, y, weights\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.unique_datetimes)\n",
    "\n",
    "\n",
    "class ModelRBase(nn.Module):\n",
    "    \"\"\"Base recurrent model.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_sizes: list, dropout_rates: list,\n",
    "                 hidden_sizes_linear: list, dropout_rates_linear: list, model_type: str) -> None:\n",
    "        super(ModelRBase, self).__init__()\n",
    "        self.num_layers = len(hidden_sizes)\n",
    "        self.gru_layers = nn.ModuleList()\n",
    "        self.dropout_rates = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            input_dim = input_size if i == 0 else hidden_sizes[i - 1]\n",
    "            if model_type == \"gru\":\n",
    "                layer = nn.GRU(input_dim, hidden_sizes[i], num_layers=1, batch_first=True)\n",
    "            elif model_type == \"lstm\":\n",
    "                layer = nn.LSTM(input_dim, hidden_sizes[i], num_layers=1, batch_first=True)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model type\")\n",
    "            self.gru_layers.append(layer)\n",
    "            self.dropout_rates.append(nn.Dropout(dropout_rates[i]))\n",
    "        n_input_linear = input_size if self.num_layers == 0 else hidden_sizes[-1]\n",
    "        fc_layers = []\n",
    "        if hidden_sizes_linear:\n",
    "            for i in range(len(hidden_sizes_linear)):\n",
    "                in_features = n_input_linear if i == 0 else hidden_sizes_linear[i - 1]\n",
    "                fc_layers.append(nn.Linear(in_features, hidden_sizes_linear[i]))\n",
    "                fc_layers.append(nn.ReLU())\n",
    "                fc_layers.append(nn.Dropout(dropout_rates_linear[i]))\n",
    "            fc_layers.append(nn.Linear(hidden_sizes_linear[-1], 1))\n",
    "        else:\n",
    "            fc_layers.append(nn.Linear(n_input_linear, 1))\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: bool = None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        D, T, _ = x.shape\n",
    "        if hidden is None:\n",
    "            hidden = [None] * self.num_layers\n",
    "        for i, gru in enumerate(self.gru_layers):\n",
    "            x, h = gru(x, hidden[i])\n",
    "            if hasattr(self, \"dropout_rates\"):\n",
    "                x = self.dropout_rates[i](x)\n",
    "            hidden[i] = h\n",
    "        x = x.reshape(D * T, -1)\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(D, T)\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "class ModelR(nn.Module):\n",
    "    \"\"\"Recurrent model with auxiliary targets.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_sizes: list, dropout_rates: list,\n",
    "                 hidden_sizes_linear: list, dropout_rates_linear: list, model_type: str):\n",
    "        super(ModelR, self).__init__()\n",
    "        self.num_resp = 4\n",
    "        self.grus = nn.ModuleList()\n",
    "        self.fcs = nn.ModuleList()\n",
    "        for _ in range(self.num_resp):\n",
    "            self.grus.append(\n",
    "                ModelRBase(input_size, hidden_sizes, dropout_rates, hidden_sizes_linear, dropout_rates_linear, model_type)\n",
    "            )\n",
    "        self.out = nn.Sequential(nn.Linear(self.num_resp, 1),)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: torch.Tensor | None = None) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        D, T, _ = x.shape\n",
    "        if hidden is None:\n",
    "            hidden = [None] * self.num_resp\n",
    "        out = []\n",
    "        for i in range(len(self.grus)):\n",
    "            z, h = self.grus[i](x, hidden[i])\n",
    "            out.append(z)\n",
    "            out[i] = out[i].reshape(D * T, -1)\n",
    "            hidden[i] = h\n",
    "        out_resp = torch.cat(out, dim=-1)\n",
    "        y = self.out(out_resp)\n",
    "        out_resp = out_resp.reshape(D, T, -1)\n",
    "        y = y.reshape(D, T)\n",
    "        return y, out_resp, hidden\n",
    "\n",
    "\n",
    "class NN:\n",
    "    \"\"\"Neural network model for time series data with auxiliary targets.\"\"\"\n",
    "\n",
    "    def __init__(self, model_type: str = None, hidden_sizes: list = None, dropout_rates: list = None,\n",
    "                 hidden_sizes_linear: list = None, dropout_rates_linear: list = None, lr: float = 0.001,\n",
    "                 batch_size: int = 1, epochs: int = 100, early_stopping_patience: int = 10, early_stopping: bool = True,\n",
    "                 lr_patience: int = 2, lr_factor: float = 0.5, lr_refit: float = 0.001, random_seed: int = 42) -> None:\n",
    "        self.model_type = model_type\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.dropout_rates = dropout_rates\n",
    "        self.hidden_sizes_linear = hidden_sizes_linear\n",
    "        self.dropout_rates_linear = dropout_rates_linear\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping = early_stopping\n",
    "        self.lr_patience = lr_patience\n",
    "        self.lr_factor = lr_factor\n",
    "        self.lr_refit = lr_refit\n",
    "        self.random_seed = random_seed\n",
    "        self.criterion = WeightedR2Loss()\n",
    "        self.device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.best_epoch = None\n",
    "        self.features = None\n",
    "\n",
    "    def fit(self, train_set: tuple, val_set: tuple, verbose: bool = False) -> None:\n",
    "        torch.manual_seed(self.random_seed)\n",
    "        train_dataset = CustomTensorDataset(*train_set, on_batch=True)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=flatten_collate_fn)\n",
    "        val_dataset = CustomTensorDataset(*val_set, on_batch=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=flatten_collate_fn)\n",
    "        self.model = ModelR(train_dataset.num_features, self.hidden_sizes, self.dropout_rates,\n",
    "                            self.hidden_sizes_linear, self.dropout_rates_linear, self.model_type).to(self.device)\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=0.01)\n",
    "        train_r2s, val_r2s = [], []\n",
    "        if verbose:\n",
    "            print(f\"Device: {self.device}\")\n",
    "            print(f\"{'Epoch':^5} | {'Train Loss':^10} | {'Val Loss':^8} | {'Train R2':^9} | {'Val R2':^7} | {'LR':^7}\")\n",
    "            print(\"-\" * 60)\n",
    "        min_val_r2 = -np.inf\n",
    "        best_epoch = 0\n",
    "        no_improvement = 0\n",
    "        best_model = None\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_r2 = self.train_one_epoch(train_dataloader, verbose)\n",
    "            val_loss, val_r2 = self.validate_one_epoch(val_dataloader, verbose)\n",
    "            lr_last = self.optimizer.param_groups[0][\"lr\"]\n",
    "            train_r2s.append(train_r2)\n",
    "            val_r2s.append(val_r2)\n",
    "            if verbose:\n",
    "                print(f\"{epoch+1:^5} | {train_loss:^10.4f} | {val_loss:^8.4f} | {train_r2:^9.4f} | {val_r2:^7.4f} | {lr_last:^7.5f}\")\n",
    "            if val_r2 > min_val_r2:\n",
    "                min_val_r2 = val_r2\n",
    "                best_model = copy.deepcopy(self.model.state_dict())\n",
    "                no_improvement = 0\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "            if self.early_stopping and no_improvement >= self.early_stopping_patience + 1:\n",
    "                self.best_epoch = best_epoch + 1\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping on epoch {best_epoch+1}. Best score: {min_val_r2:.4f}\")\n",
    "                break\n",
    "        if self.early_stopping:\n",
    "            self.model.load_state_dict(best_model)\n",
    "\n",
    "    def train_one_epoch(self, train_dataloader: DataLoader, verbose: bool) -> tuple[float, float]:\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        y_total, weights_total, preds_total = [], [], []\n",
    "        itr = tqdm(train_dataloader) if verbose else train_dataloader\n",
    "        for x_batch, resp_batch, y_batch, weights_batch in itr:\n",
    "            x_batch, resp_batch, y_batch, weights_batch = (item.to(self.device) for item in [x_batch, resp_batch, y_batch, weights_batch])\n",
    "            self.optimizer.zero_grad()\n",
    "            out_y, out_resp, _ = self.model(x_batch, None)\n",
    "            loss1 = self.criterion(out_y.flatten(), y_batch.flatten(), weights_batch.flatten())\n",
    "            loss2 = self.criterion(out_resp[:, :, 0].flatten(), resp_batch[:, :, -1].flatten(), weights_batch.flatten())\n",
    "            loss3 = self.criterion(out_resp[:, :, 1].flatten(), resp_batch[:, :, -2].flatten(), weights_batch.flatten())\n",
    "            loss4 = self.criterion(out_resp[:, :, 2].flatten(), resp_batch[:, :, -3].flatten(), weights_batch.flatten())\n",
    "            loss5 = self.criterion(out_resp[:, :, 3].flatten(), resp_batch[:, :, -4].flatten(), weights_batch.flatten())\n",
    "            loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            y_total.append(y_batch.flatten())\n",
    "            weights_total.append(weights_batch.flatten())\n",
    "            preds_total.append(out_y.detach().flatten())\n",
    "        y_total = torch.cat(y_total).cpu()\n",
    "        weights_total = torch.cat(weights_total).cpu()\n",
    "        preds_total = torch.cat(preds_total).cpu()\n",
    "        train_r2 = r2_weighted_torch(y_total, preds_total, weights_total).item()\n",
    "        train_loss = total_loss / len(train_dataloader)\n",
    "        return train_loss, train_r2\n",
    "\n",
    "    def validate_one_epoch(self, val_dataloader: DataLoader, verbose=False) -> tuple[float, float]:\n",
    "        model = copy.deepcopy(self.model)\n",
    "        losses, all_y, all_weights, all_preds = [], [], [], []\n",
    "        itr = tqdm(val_dataloader) if verbose else val_dataloader\n",
    "        for x_batch, resp_batch, y_batch, weights_batch in itr:\n",
    "            x_batch, resp_batch, y_batch, weights_batch = (item.to(self.device) for item in [x_batch, resp_batch, y_batch, weights_batch])\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                preds_batch, _, _ = model(x_batch, None)\n",
    "                loss = self.criterion(preds_batch.flatten(), y_batch.flatten(), weights_batch.flatten())\n",
    "                losses.append(loss.item())\n",
    "                all_y.append(y_batch.flatten())\n",
    "                all_weights.append(weights_batch.flatten())\n",
    "                all_preds.append(preds_batch.flatten())\n",
    "            if self.lr_refit > 0:\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr_refit, weight_decay=0.01)\n",
    "                optimizer.zero_grad()\n",
    "                model.train()\n",
    "                out_y, _, _ = model(x_batch, None)\n",
    "                loss = self.criterion(out_y, y_batch, weights_batch)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_weights = torch.cat(all_weights)\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        loss = np.mean(losses)\n",
    "        r2 = r2_weighted_torch(all_y, all_preds, all_weights).item()\n",
    "        return loss, r2\n",
    "\n",
    "    def update(self, X: np.array, y: np.array, weights: np.array, n_times: int):\n",
    "        if self.lr_refit == 0.0:\n",
    "            return\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        weights = torch.tensor(weights, dtype=torch.float32)\n",
    "        N, K = X.shape\n",
    "        X = X.view(n_times, N // n_times, K).swapaxes(0, 1).to(self.device)\n",
    "        y = y.view(n_times, N // n_times).swapaxes(0, 1).to(self.device)\n",
    "        weights = weights.view(n_times, N // n_times).swapaxes(0, 1).to(self.device)\n",
    "        self.model.train()\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr_refit, weight_decay=0.01)\n",
    "        optimizer.zero_grad()\n",
    "        out_y, _, _ = self.model(X, None)\n",
    "        loss = self.criterion(out_y.flatten(), y.flatten(), weights.flatten())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    def predict(self, X: np.array, n_times: int = None, hidden: torch.Tensor | list | None = None) -> tuple[np.array, torch.Tensor | list]:\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        N, K = X.shape\n",
    "        X_tensor = X_tensor.view(n_times, N // n_times, K).swapaxes(0, 1).to(self.device)\n",
    "        X_tensor = torch.nan_to_num(X_tensor, 0)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds, _, hidden = self.model(X_tensor, hidden)\n",
    "            preds = preds.swapaxes(0, 1)\n",
    "            preds = preds.reshape(-1).cpu().numpy()\n",
    "        return preds, hidden\n",
    "\n",
    "    def get_params(self, deep: bool = True):\n",
    "        return {\n",
    "            \"model_type\": self.model_type,\n",
    "            \"hidden_sizes\": self.hidden_sizes,\n",
    "            \"dropout_rates\": self.dropout_rates,\n",
    "            \"hidden_sizes_linear\": self.hidden_sizes_linear,\n",
    "            \"dropout_rates_linear\": self.dropout_rates_linear,\n",
    "            \"lr\": self.lr,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"early_stopping_patience\": self.early_stopping_patience,\n",
    "            \"early_stopping\": self.early_stopping,\n",
    "            \"lr_patience\": self.lr_patience,\n",
    "            \"lr_factor\": self.lr_factor,\n",
    "            \"lr_refit\": self.lr_refit,\n",
    "            \"random_seed\": self.random_seed\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBM(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"LightGBM model.\"\"\"\n",
    "\n",
    "    def __init__(self, params: dict, early_stopping: bool = True, early_stopping_rounds: int = 50,\n",
    "                 test_size: float = 0.05, features: str = None, features_cat: list | None = None,\n",
    "                 shuffle: bool = False, classifier: bool = False) -> None:\n",
    "        self.params = params\n",
    "        self.early_stopping = early_stopping\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.features = features\n",
    "        self.features_cat = features_cat\n",
    "        self.shuffle = shuffle\n",
    "        if classifier:\n",
    "            self.model = lgb.LGBMClassifier(**params)\n",
    "        else:\n",
    "            self.model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    def fit(self, train_set, val_set, verbose: bool = False) -> None:\n",
    "        X_train, y_train, weights_train, _, _, _ = train_set\n",
    "        if not self.early_stopping:\n",
    "            eval_set = [(X_train, y_train)]\n",
    "            eval_weights_set = [weights_train]\n",
    "            callbacks = [lgb.callback.log_evaluation(50 if verbose else 0)]\n",
    "        else:\n",
    "            X_val, y_val, weights_val, _, _, _ = val_set\n",
    "            eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "            eval_weights_set = [weights_train, weights_val]\n",
    "            callbacks = [\n",
    "                lgb.callback.log_evaluation(50 if verbose else 0),\n",
    "                lgb.callback.early_stopping(stopping_rounds=self.early_stopping_rounds, verbose=verbose)\n",
    "            ]\n",
    "        self.model.fit(X_train, y_train,\n",
    "                       sample_weight=weights_train,\n",
    "                       eval_metric=[r2_lgb],\n",
    "                       eval_set=eval_set,\n",
    "                       eval_sample_weight=eval_weights_set,\n",
    "                       feature_name=self.features,\n",
    "                       categorical_feature=self.features_cat,\n",
    "                       callbacks=callbacks)\n",
    "        return self\n",
    "\n",
    "    def update(self, X, stocks, y, weights, dates, times):\n",
    "        self.model.learning_rate = self.lr_refit\n",
    "        self.model.fit(X, y, sample_weight=weights, feature_name=self.features, init_model=self.model,\n",
    "                       callbacks=[lgb.callback.log_evaluation(1)])\n",
    "\n",
    "    def predict(self, X: np.array, *args, **kwargs) -> np.array:\n",
    "        return self.model.predict(X), None\n",
    "\n",
    "    def get_feature_importances(self) -> None:\n",
    "        imp_df = pd.DataFrame({\n",
    "            \"feature\": self.features,\n",
    "            \"imp\": self.model.feature_importances_\n",
    "        })\n",
    "        imp_df.sort_values(\"imp\", ascending=False, inplace=True)\n",
    "        imp_df[\"imp_acc\"] = imp_df[\"imp\"].cumsum() / imp_df[\"imp\"].sum()\n",
    "        imp_df.set_index(\"feature\", inplace=True)\n",
    "        return imp_df\n",
    "\n",
    "    def set_seed(self, seed: int) -> None:\n",
    "        self.params[\"random_state\"] = seed\n",
    "\n",
    "    def get_params(self, deep: bool = True):\n",
    "        return {\n",
    "            \"params\": self.params,\n",
    "            \"early_stopping\": self.early_stopping,\n",
    "            \"early_stopping_rounds\": self.early_stopping_rounds,\n",
    "            \"test_size\": self.test_size,\n",
    "            \"features\": self.features,\n",
    "            \"shuffle\": self.shuffle,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "class CBM(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"CBM model.\"\"\"\n",
    "\n",
    "    def __init__(self, params: dict, early_stopping: bool = True, early_stopping_rounds: int = 50,\n",
    "                 test_size: float = 0.05, features: str = None, shuffle: bool = False) -> None:\n",
    "        self.params = params\n",
    "        self.early_stopping = early_stopping\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.model = cb.CatBoostRegressor(**params, eval_metric=r2_cbt(), early_stopping_rounds=early_stopping_rounds)\n",
    "        self.cat_cols = None\n",
    "\n",
    "    def fit(self, train_set, val_set, test_set=None, cat_cols: list = None, verbose: bool = False) -> None:\n",
    "        X_train, y_train, weights_train, _, _, _ = train_set\n",
    "        self.cat_cols = cat_cols\n",
    "        if not self.early_stopping:\n",
    "            train_pool = cb.Pool(X_train, y_train, weight=weights_train, cat_features=cat_cols)\n",
    "            eval_set = None\n",
    "        else:\n",
    "            X_val, y_val, weights_val, _, _, _ = val_set\n",
    "            train_pool = cb.Pool(X_train, y_train, weight=weights_train, cat_features=cat_cols)\n",
    "            val_pool = cb.Pool(X_val, y_val, weight=weights_val, cat_features=cat_cols)\n",
    "            eval_set = val_pool\n",
    "        self.model.set_feature_names(self.features)\n",
    "        self.model.fit(train_pool, eval_set=eval_set, verbose=1 if verbose else 0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.array, *args, **kwargs) -> np.array:\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def get_feature_importances(self) -> None:\n",
    "        imp_df = pd.DataFrame({\n",
    "            \"feature\": self.features,\n",
    "            \"imp\": self.model.feature_importances_\n",
    "        })\n",
    "        imp_df.sort_values(\"imp\", ascending=False, inplace=True)\n",
    "        imp_df[\"imp_acc\"] = imp_df[\"imp\"].cumsum() / imp_df[\"imp\"].sum()\n",
    "        imp_df.set_index(\"feature\", inplace=True)\n",
    "        return imp_df\n",
    "\n",
    "    def set_seed(self, seed: int) -> None:\n",
    "        self.params[\"random_state\"] = seed\n",
    "\n",
    "    def get_params(self, deep: bool = True):\n",
    "        return {\n",
    "            \"params\": self.params,\n",
    "            \"early_stopping\": self.early_stopping,\n",
    "            \"early_stopping_rounds\": self.early_stopping_rounds,\n",
    "            \"test_size\": self.test_size,\n",
    "            \"features\": self.features,\n",
    "            \"shuffle\": self.shuffle,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "class XGBM(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"XGBoost model.\"\"\"\n",
    "\n",
    "    def __init__(self, params: dict, early_stopping: bool = True, early_stopping_rounds=50,\n",
    "                 test_size: float = 0.05, features: str = None, shuffle: bool = False):\n",
    "        self.params = params\n",
    "        self.early_stopping = early_stopping\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.test_size = test_size\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.model = xgb.XGBRegressor(**params, early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array, weights: np.array, verbose: bool = False) -> None:\n",
    "        if not self.early_stopping:\n",
    "            X_train, y_train, weights_train = X, y, weights\n",
    "            eval_set = [(X_train, y_train)]\n",
    "            eval_sample_weight = [weights_train]\n",
    "        else:\n",
    "            X_train, X_val, y_train, y_val, weights_train, weights_val = train_test_split(\n",
    "                X, y, weights, test_size=self.test_size, shuffle=self.shuffle,\n",
    "                random_state=RANDOM_SEED if self.shuffle else None\n",
    "            )\n",
    "            eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "            eval_sample_weight = [weights_train, weights_val]\n",
    "        self.model.fit(X_train, y_train, sample_weight=weights_train,\n",
    "                       eval_set=eval_set, eval_sample_weight=eval_sample_weight,\n",
    "                       feature_names=self.features, verbose=50 if verbose else 0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def set_seed(self, seed: int) -> None:\n",
    "        self.params[\"random_state\"] = seed\n",
    "\n",
    "    def get_params(self, deep: bool = True):\n",
    "        return {\n",
    "            \"params\": self.params,\n",
    "            \"early_stopping\": self.early_stopping,\n",
    "            \"early_stopping_rounds\": self.early_stopping_rounds,\n",
    "            \"test_size\": self.test_size,\n",
    "            \"features\": self.features,\n",
    "            \"shuffle\": self.shuffle,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Custom Pipeline Classes\n",
    "\n",
    "* Manage model training, ensembling, and cross-validation on time series data, including:\n",
    "    * FullPipeline: Manages model training, saving/loading, and real-time updates.\n",
    "    * PipelineEnsemble: Averages predictions from multiple models.\n",
    "    * PipelineCV: Handles time series cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullPipeline:\n",
    "    \"\"\"\n",
    "    Custom pipeline for model management and time series training.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: BaseEstimator, preprocessor=None, run_name: str = \"\", name: str = \"\",\n",
    "                 load_model: bool = False, features: list | None = None, save_to_disc: bool = True,\n",
    "                 refit=True, change_lr=False, col_target=COL_TARGET) -> None:\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.name = name\n",
    "        self.load_model = load_model\n",
    "        self.features = features\n",
    "        self.save_to_disc = save_to_disc\n",
    "        self.refit = refit\n",
    "        self.change_lr = change_lr\n",
    "        self.col_target = col_target\n",
    "\n",
    "        self.responders = [i for i in COLS_RESPONDERS if i != self.col_target]\n",
    "\n",
    "        self.set_run_name(run_name)\n",
    "        self.path = os.path.join(PATH_MODELS, f\"{self.run_name}\")\n",
    "\n",
    "    def set_run_name(self, run_name: str) -> None:\n",
    "        self.run_name = run_name\n",
    "        self.path = os.path.join(PATH_MODELS, f\"{self.run_name}\")\n",
    "        if self.save_to_disc:\n",
    "            create_folder(self.path)\n",
    "\n",
    "    def fit(self, df: pl.DataFrame | None = None, df_valid: pl.DataFrame | None = None, verbose: bool = False) -> None:\n",
    "        if not self.load_model:\n",
    "            self.model.features = self.features\n",
    "\n",
    "            weights_train = df.select(COL_WEIGHT).to_series().to_numpy()\n",
    "            dates_train = df.select(COL_DATE).to_series().to_numpy()\n",
    "            times_train = df.select(COL_TIME).to_series().to_numpy()\n",
    "            stocks_train = df.select(COL_ID).to_series().to_numpy()\n",
    "\n",
    "            weights_valid = df_valid.select(COL_WEIGHT).to_series().to_numpy()\n",
    "            dates_valid = df_valid.select(COL_DATE).to_series().to_numpy()\n",
    "            times_valid = df_valid.select(COL_TIME).to_series().to_numpy()\n",
    "            stocks_valid = df_valid.select(COL_ID).to_series().to_numpy()\n",
    "\n",
    "            if self.preprocessor is not None:\n",
    "                df = self.preprocessor.fit_transform(df)\n",
    "                df_valid = self.preprocessor.transform(df_valid)\n",
    "\n",
    "            X_train = df.select(self.features).to_numpy()\n",
    "            resp_train = df.select(self.responders).to_numpy()\n",
    "            y_train = df.select(self.col_target).to_series().to_numpy()\n",
    "\n",
    "            X_valid = df_valid.select(self.features).to_numpy()\n",
    "            resp_valid = df_valid.select(self.responders).to_numpy()\n",
    "            y_valid = df_valid.select(self.col_target).to_series().to_numpy()\n",
    "\n",
    "            train_set = (X_train, resp_train, y_train, weights_train, stocks_train, dates_train, times_train)\n",
    "            val_set = (X_valid, resp_valid, y_valid, weights_valid, stocks_valid, dates_valid, times_valid)\n",
    "\n",
    "            del df, df_valid\n",
    "            gc.collect()\n",
    "\n",
    "            self.model.fit(train_set, val_set, verbose)\n",
    "            if self.save_to_disc:\n",
    "                self.save()\n",
    "        else:\n",
    "            self.load()\n",
    "\n",
    "    def predict(self, df: pl.DataFrame, hidden: torch.Tensor | list | None = None, n_times: int | None = None) -> tuple[np.ndarray, torch.Tensor | list]:\n",
    "        if n_times is None:\n",
    "            n_times = len(df.select(COL_TIME).unique())\n",
    "        if self.preprocessor is not None:\n",
    "            df = self.preprocessor.transform(df)\n",
    "        X = df.select(self.features).to_numpy()\n",
    "        preds, hidden = self.model.predict(X, hidden=hidden, n_times=n_times)\n",
    "        preds = np.clip(preds, -5, 5)  # per competition requirements\n",
    "        return preds, hidden\n",
    "\n",
    "    def update(self, df: pl.DataFrame) -> None:\n",
    "        weights = df.select(COL_WEIGHT).to_series().to_numpy()\n",
    "        n_times = len(df.select(COL_TIME).unique())\n",
    "        if self.preprocessor is not None:\n",
    "            df = self.preprocessor.transform(df, refit=True)\n",
    "\n",
    "        X = df.select(self.features).to_numpy()\n",
    "        y = df.select(self.col_target).to_series().to_numpy()\n",
    "        self.model.update(X, y, weights, n_times)\n",
    "\n",
    "    def load(self) -> None:\n",
    "        if self.change_lr:\n",
    "            lr_refit = self.model.lr_refit\n",
    "        self.model = joblib.load(f\"{self.path}/model_{self.name}.joblib\")\n",
    "        self.features = self.model.features\n",
    "        if self.change_lr:\n",
    "            self.model.lr_refit = lr_refit\n",
    "        try:\n",
    "            self.preprocessor = joblib.load(f\"{self.path}/preprocessor_{self.name}.joblib\")\n",
    "        except FileNotFoundError:\n",
    "            self.preprocessor = None\n",
    "            print(\"WARNING: Preprocessor not found.\")\n",
    "\n",
    "    def save(self) -> None:\n",
    "        joblib.dump(self.model, f\"{self.path}/model_{self.name}.joblib\")\n",
    "        if self.preprocessor is not None:\n",
    "            joblib.dump(self.preprocessor, f\"{self.path}/preprocessor_{self.name}.joblib\")\n",
    "\n",
    "    def get_params(self, deep: bool = True) -> dict:\n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"preprocessor\": self.preprocessor,\n",
    "            \"name\": self.name,\n",
    "            \"load_model\": self.load_model,\n",
    "            \"features\": self.features,\n",
    "            \"save_to_disc\": self.save_to_disc,\n",
    "            \"refit\": self.refit,\n",
    "            \"change_lr\": self.change_lr,\n",
    "            \"col_target\": self.col_target,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "class PipelineEnsemble:\n",
    "    \"\"\"\n",
    "    Ensemble pipeline for aggregating predictions from multiple models.\n",
    "    \"\"\"\n",
    "    def __init__(self, models: list, weights: np.array = None, refit_models: list[bool] = None, col_target: str = COL_TARGET) -> None:\n",
    "        self.models = models\n",
    "        self.weights = weights if weights is not None else np.ones(len(self.models))\n",
    "        self.refit_models = refit_models if refit_models is not None else [True] * len(models)\n",
    "        self.col_target = col_target\n",
    "        self.refit = True\n",
    "\n",
    "    def fit(self, df: pl.DataFrame | None = None, df_valid: pl.DataFrame | None = None, verbose: bool = False) -> None:\n",
    "        self.weights = np.array(self.weights) / sum(self.weights)\n",
    "        for model in self.models:\n",
    "            model.fit(df, df_valid, verbose)\n",
    "\n",
    "    def set_run_name(self, run_name: str) -> None:\n",
    "        for model in self.models:\n",
    "            model.set_run_name(run_name)\n",
    "\n",
    "    def predict(self, df: pl.DataFrame, hidden_ls=None) -> np.ndarray:\n",
    "        if hidden_ls is None:\n",
    "            hidden_ls = [None] * len(self.models)\n",
    "\n",
    "        preds = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            preds_i, hidden_ls[i] = model.predict(df, hidden=hidden_ls[i])\n",
    "            preds.append(preds_i)\n",
    "\n",
    "        preds = np.average(preds, axis=0, weights=self.weights)\n",
    "        return preds, hidden_ls\n",
    "\n",
    "    def update(self, df: pl.DataFrame) -> None:\n",
    "        for i, model in enumerate(self.models):\n",
    "            if self.refit_models[i]:\n",
    "                model.update(df)\n",
    "\n",
    "    def load(self) -> None:\n",
    "        for model in self.models:\n",
    "            model.model.load()\n",
    "\n",
    "    def save(self) -> None:\n",
    "        for model in self.models:\n",
    "            model.model.save()\n",
    "\n",
    "    def get_params(self, deep: bool = True) -> dict:\n",
    "        return {\n",
    "            \"models\": self.models,\n",
    "            \"weights\": self.weights,\n",
    "            \"refit_models\": self.refit_models,\n",
    "            \"col_target\": self.col_target,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "class PipelineCV:\n",
    "    \"\"\"\n",
    "    Cross-validation pipeline for time series models.\n",
    "    \"\"\"\n",
    "    def __init__(self, model: FullPipeline, tracker: WandbTracker, n_splits: int, train_size: int = False) -> None:\n",
    "        self.model = model\n",
    "        self.tracker = tracker\n",
    "        self.n_splits = n_splits\n",
    "        self.train_size = train_size\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, df: pl.DataFrame, verbose: bool = False) -> list:\n",
    "        dates_unique = df.select(pl.col(COL_DATE).unique().sort()).to_series().to_numpy()\n",
    "\n",
    "        test_size = (\n",
    "            TEST_SIZE\n",
    "            if len(dates_unique) > TEST_SIZE * (self.n_splits + 1)\n",
    "            else len(dates_unique) // (self.n_splits + 1)\n",
    "        )\n",
    "        cv = TimeSeriesSplit(\n",
    "            n_splits=self.n_splits,\n",
    "            test_size=test_size,\n",
    "            max_train_size=self.train_size\n",
    "        )\n",
    "        cv_split = cv.split(dates_unique)\n",
    "\n",
    "        scores = []\n",
    "        for fold, (train_idx, valid_idx) in enumerate(cv_split):\n",
    "            if verbose:\n",
    "                print(\"-\" * 20 + f\"Fold {fold}\" + \"-\" * 20)\n",
    "                print(f\"Train dates from {dates_unique[train_idx].min()} to {dates_unique[train_idx].max()}\")\n",
    "                print(f\"Valid dates from {dates_unique[valid_idx].min()} to {dates_unique[valid_idx].max()}\")\n",
    "\n",
    "            dates_train = dates_unique[train_idx]\n",
    "            dates_valid = dates_unique[valid_idx]\n",
    "\n",
    "            df_train = df.filter(pl.col(COL_DATE).is_in(dates_train))\n",
    "            df_valid = df.filter(pl.col(COL_DATE).is_in(dates_valid))\n",
    "\n",
    "            model_fold = clone(self.model)\n",
    "            model_fold.set_run_name(f\"fold{fold}\")\n",
    "            model_fold.fit(df_train, df_valid, verbose=verbose)\n",
    "\n",
    "            self.models.append(model_fold)\n",
    "\n",
    "            preds = []\n",
    "            cnt_dates = 0\n",
    "            model_save = copy.deepcopy(model_fold)\n",
    "            for date_id in tqdm(dates_valid):\n",
    "                df_valid_date = df_valid.filter(pl.col(COL_DATE) == date_id)\n",
    "\n",
    "                if model_fold.refit & (cnt_dates > 0):\n",
    "                    df_upd = df.filter(pl.col(COL_DATE) == date_id - 1)\n",
    "                    if len(df_upd) > 0:\n",
    "                        model_save.update(df_upd)\n",
    "\n",
    "                preds_i, _ = model_save.predict(df_valid_date)\n",
    "                preds += list(preds_i)\n",
    "                cnt_dates += 1\n",
    "            preds = np.array(preds)\n",
    "\n",
    "            df_valid = df_valid.fill_null(0.0)\n",
    "            y_true = df_valid.select(pl.col(model_fold.col_target)).to_series().to_numpy()\n",
    "            weights = df_valid.select(pl.col(COL_WEIGHT)).to_series().to_numpy()\n",
    "            score = r2_weighted(y_true, preds, weights)\n",
    "            scores.append(score)\n",
    "\n",
    "            print(f\"R2: {score:.5f}\")\n",
    "            if self.tracker:\n",
    "                self.tracker.log_metrics({f\"fold_{fold}\": score})\n",
    "\n",
    "        if self.tracker:\n",
    "            self.tracker.log_metrics({\"cv\": np.mean(scores)})\n",
    "        return scores\n",
    "\n",
    "    def load(self) -> None:\n",
    "        self.models = []\n",
    "        for i in range(self.n_splits):\n",
    "            model = clone(self.model)\n",
    "            model.set_run_name(f\"fold{i}\")\n",
    "            model.fit()\n",
    "            self.models.append(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the data processor (handles cleaning and feature engineering)\n",
    "data_processor = DataProcessor(MODEL_NAMES[0]).load()\n",
    "\n",
    "# Instantiate the pipeline objects for each model.\n",
    "pipelines = {}\n",
    "for model_name in MODEL_NAMES:\n",
    "    pipeline = FullPipeline(\n",
    "        None,\n",
    "        run_name=RUN_NAME,\n",
    "        name=model_name,\n",
    "        load_model=True,\n",
    "        features=None,\n",
    "        save_to_disc=False\n",
    "    )\n",
    "    pipeline.fit(verbose=True)\n",
    "    pipelines[model_name] = pipeline\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(model_name)\n",
    "    print(pipeline.model.get_params())\n",
    "    print(f\"Number of features: {len(pipeline.features)}\")\n",
    "    print(pipeline.model.model.num_resp)\n",
    "\n",
    "df_raw = pl.scan_parquet(f\"{PATH_DATA}/train.parquet\")\n",
    "df_raw = df_raw.filter(pl.col(\"date_id\") >= MAX_DATE - 10)\n",
    "df_raw = df_raw.collect()\n",
    "df_raw = df_raw.with_columns(\n",
    "    pl.lit(-1).cast(pl.Int64).alias(\"row_id\"),\n",
    "    pl.lit(True).alias(\"is_scored\"),\n",
    "    (pl.col(\"date_id\") - MAX_DATE - 1).alias(\"date_id\")\n",
    ")\n",
    "df_raw = df_raw.select(COLS_ID + data_processor.COLS_FEATURES_INIT)\n",
    "\n",
    "df_raw = (\n",
    "    df_raw.filter(pl.col(\"date_id\") >= -5)\n",
    "    .sort(['date_id', 'time_id', 'symbol_id'])\n",
    ")\n",
    "\n",
    "# Global variables used by the inference function\n",
    "hidden_states = [None] * len(pipelines)\n",
    "dfs = []\n",
    "\n",
    "time_start = time.time()\n",
    "time_start_not_scored = time.time()\n",
    "time_est = 0\n",
    "time_est_not_scored = 0\n",
    "cnt_dates = 0\n",
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction given the latest test data and lag features.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    global df_raw, hidden_states, pipelines, dfs, time_est, time_start, time_start_not_scored, time_est_not_scored, cnt_dates\n",
    "    \n",
    "    date_id = test[\"date_id\"][0]\n",
    "    time_id = test[\"time_id\"][0]\n",
    "    is_scored = test[\"is_scored\"][0]\n",
    "\n",
    "    # For debugging purposes: measure elapsed time\n",
    "    if DEBUG:\n",
    "        if not is_scored:\n",
    "            time_est_not_scored = time.time() - time_start_not_scored\n",
    "        else:\n",
    "            time_est = time.time() - time_start\n",
    "\n",
    "        if time_id == 0:\n",
    "            print(\"-\" * 100)\n",
    "            if date_id == 1:\n",
    "                time_start_not_scored = time.time()\n",
    "            if date_id == CNT_DATES_NOT_SCORED: \n",
    "                time_start = time.time()\n",
    "\n",
    "    # Reset hidden states and accumulate data for weight updates\n",
    "    if time_id == 0:\n",
    "        cnt_dates += 1\n",
    "        hidden_states = [None for _ in pipelines]\n",
    "        lags = lags.with_columns(\n",
    "            pl.col(\"responder_6_lag_1\").alias(\"responder_6\"),\n",
    "            pl.lit(date_id - 1).cast(pl.Int16).alias(\"date_id\")\n",
    "        ).select([\"date_id\", \"time_id\", \"symbol_id\", \"responder_6\"])\n",
    "        if cnt_dates > 1:\n",
    "            df = pl.concat(dfs)  # append the previous test data\n",
    "            dfs = []            # reset the container\n",
    "            df = df.join(lags, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "            df = df.sort([\"date_id\", \"time_id\", \"symbol_id\"])\n",
    "\n",
    "    # Append new test data to raw data and trim to the latest N_ROLL observations per symbol\n",
    "    test = test.select(df_raw.columns)\n",
    "    df_raw = pl.concat([df_raw, test], how=\"vertical_relaxed\")\n",
    "    df_raw = df_raw.select(test.columns)\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .group_by([\"symbol_id\"])\n",
    "        .tail(N_ROLL)\n",
    "    )\n",
    "\n",
    "    # Process current features using the data processor\n",
    "    df_cur = data_processor.process_test_data(df_raw, fast=True, date_id=date_id, time_id=time_id, symbols=test[\"symbol_id\"])\n",
    "    df_cur = df_cur.sort([\"symbol_id\"])\n",
    "    dfs.append(df_cur)\n",
    "    df_cur = df_cur.with_columns(pl.lit(None).alias(\"responder_6\"))\n",
    "    \n",
    "    # Update model weights with accumulated data (if enough data is available)\n",
    "    if (time_id == 0) & (cnt_dates > 1):\n",
    "        if len(df) > 968:  # need more than 1 day of data to update\n",
    "            for i, (name, pipeline) in enumerate(pipelines.items()):\n",
    "                pipeline.update(df)\n",
    "\n",
    "    # Generate predictions only if the test sample is scored\n",
    "    if is_scored:\n",
    "        preds = []\n",
    "        for i, (name, pipeline) in enumerate(pipelines.items()):\n",
    "            pred, hidden_states[i] = pipeline.predict(df_cur, hidden=hidden_states[i], n_times=1)\n",
    "            preds.append(pred)\n",
    "        pred = np.average(preds, axis=0, weights=WEIGHTS)\n",
    "    \n",
    "        df_cur = df_cur.with_columns(pl.Series(\"responder_6\", pred))\n",
    "        df_cur = test.select([\"date_id\", \"time_id\", \"symbol_id\"]).join(df_cur, on=[\"date_id\", \"time_id\", \"symbol_id\"], how=\"left\")\n",
    "        predictions = df_cur.select([\"row_id\", \"responder_6\"])\n",
    "    else:\n",
    "        predictions = test.select(\n",
    "            'row_id',\n",
    "            pl.lit(0.0).alias('responder_6'),\n",
    "        )\n",
    "\n",
    "    if DEBUG:\n",
    "        if time_id % 100 == 0:\n",
    "            n_nans = sum(sum(predictions.fill_nan(None).null_count().to_numpy()))\n",
    "            print(\n",
    "                f\"{date_id} {time_id:3.0f} (is_scored {is_scored}): \"\n",
    "                f\"time elps {time.time() - start_time:.4f}, # nans {n_nans}\"\n",
    "            )\n",
    "    else:\n",
    "        if (time_id == 0) & (date_id == 0):\n",
    "            print(predictions)\n",
    "            print((time_id, time.time() - start_time))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Initialize the inference server using our predict function\n",
    "inference_server = jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    if not DEBUG:\n",
    "        inference_server.run_local_gateway(\n",
    "            (\n",
    "                f'{PATH_DATA}/test.parquet',\n",
    "                f'{PATH_DATA}/lags.parquet',\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        inference_server.run_local_gateway(\n",
    "            (\n",
    "                '/kaggle/input/js24-rmf-submission-api-debug-with-synthetic-test/synthetic_test.parquet',\n",
    "                '/kaggle/input/js24-rmf-submission-api-debug-with-synthetic-test/synthetic_lag.parquet',\n",
    "            )\n",
    "        )\n",
    "\n",
    "if DEBUG:\n",
    "    time_est_cur = time_est / (CNT_DATES - CNT_DATES_NOT_SCORED) * 200 / 60 / 60\n",
    "    time_est_scored = time_est / (CNT_DATES - CNT_DATES_NOT_SCORED) * 120 / 60 / 60\n",
    "    time_est_not_scored = time_est_not_scored / (CNT_DATES_NOT_SCORED - 1) * 240 / 60 / 60\n",
    "    time_est_final = time_est_scored + time_est_not_scored\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Estimated current time: {time_est_cur:.4f}\")\n",
    "    print(f\"Estimated final time (is_score=True): {time_est_scored:.4f}\")\n",
    "    print(f\"Estimated final time (is_score=False): {time_est_not_scored:.4f}\")\n",
    "    print(f\"Estimated final time: {time_est_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Analysis\n",
    "\n",
    "* Functions for in‐depth model analysis.\n",
    "* Perform feature selection using neural networks.\n",
    "* Calculate null importances to help distinguish signal from noise\n",
    "* Apply adversarial validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(\n",
    "        features: list,\n",
    "        score_func: callable,\n",
    "        features_all: list | None = None,\n",
    "        method: str = \"forward\",\n",
    "        fast: bool = False,\n",
    "        superfast: bool = False,\n",
    "        shuffle: bool = False,\n",
    "        chunk_size: int = 1,\n",
    "        threshold: float = 0.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Backward/forward feature selection.\n",
    "    \"\"\"\n",
    "    def chunks(lst, chunk_size):\n",
    "        for i in range(0, len(lst), chunk_size):\n",
    "            yield lst[i:i + chunk_size]\n",
    "\n",
    "    features_incl = features.copy()\n",
    "    features_selected = []\n",
    "    if method == \"forward\":\n",
    "        features_left = [i for i in features_all if i not in features_incl]\n",
    "    else:\n",
    "        features_left = features_all.copy()\n",
    "\n",
    "    res_df = pd.DataFrame(index=features_left)\n",
    "\n",
    "    if len(features_incl) > 0:\n",
    "        score = score_func(features=features_incl)\n",
    "        score_best = score\n",
    "        print(f\"Initial score: {score_best:.4f}\")\n",
    "    else:\n",
    "        score_best = 0.0\n",
    "        print(f\"No initial features. Initial score: {score_best:.4f}\")\n",
    "\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        res_df[cnt] = np.nan\n",
    "        feature_selected = None\n",
    "        if shuffle:\n",
    "            random.shuffle(features_left)\n",
    "        pbar = tqdm(\n",
    "            chunks(features_left, chunk_size),\n",
    "            total=len(features_left) // chunk_size\n",
    "        )\n",
    "        cnt1 = 0\n",
    "        for f in pbar:\n",
    "            features_tmp = features_incl.copy()\n",
    "            if method == \"forward\":\n",
    "                features_tmp.extend(f)\n",
    "            else:\n",
    "                for i in f:\n",
    "                    features_tmp.remove(i)\n",
    "            score = score_func(features=features_tmp)\n",
    "\n",
    "            res_df.loc[f, cnt] = score\n",
    "\n",
    "            cnt1 += len(f)\n",
    "\n",
    "            print(f\"score {score:.4f}: {f}\")\n",
    "\n",
    "            if score - score_best > threshold:\n",
    "                score_best = score\n",
    "                feature_selected = f\n",
    "                if fast:\n",
    "                    break\n",
    "\n",
    "        if feature_selected is not None:\n",
    "            if method == \"forward\":\n",
    "                features_incl.extend(feature_selected)\n",
    "            else:\n",
    "                for i in feature_selected:\n",
    "                    features_incl.remove(i)\n",
    "            features_selected.extend(feature_selected)\n",
    "            if superfast:\n",
    "                features_left = features_left[cnt1:]\n",
    "            else:\n",
    "                for i in feature_selected:\n",
    "                    features_left.remove(i)\n",
    "            print(f\"Score {score_best:.4f}. {feature_selected} was selected.\")\n",
    "            print(features_selected)\n",
    "        else:\n",
    "            print(f\"Score {score_best:.4f}. No good features left. Stopping.\")\n",
    "            break\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def get_null_imp(\n",
    "    df: pd.DataFrame,\n",
    "    features: list,\n",
    "    model_name: str,\n",
    "    params: dict,\n",
    "    n: int = 10\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get null importances for the features.\n",
    "    \"\"\"\n",
    "    params_null = params.copy()\n",
    "    params_null[\"n_estimators\"] = 300\n",
    "    model = LGBM(\n",
    "        params_null,\n",
    "        early_stopping=False,\n",
    "        test_size=0.01,\n",
    "        shuffle=True\n",
    "    )\n",
    "    imps = []\n",
    "    for i in range(n):\n",
    "        df[\"target_shuffled\"] = df[\"target\"].sample(frac=1, random_state=i).values\n",
    "        name = f\"{model_name}_null_{i}\"\n",
    "        pipeline = FullPipeline(\n",
    "            Pipeline(steps=[('model', model)]),\n",
    "            run_name=\"full\",\n",
    "            name=name,\n",
    "            load_model=False,\n",
    "            features=features,\n",
    "            target_col=\"target_shuffled\",\n",
    "        )\n",
    "        pipeline.fit(df, verbose=True)\n",
    "\n",
    "        feat_imp = pipeline.model[\"model\"].get_feature_importances()\n",
    "        suffixed_importances = feat_imp[[\"imp\"]].add_suffix(f\"_{i}\")\n",
    "        imps.append(suffixed_importances)\n",
    "\n",
    "    imp_df = pd.concat(imps, axis=1)\n",
    "    return imp_df\n",
    "\n",
    "\n",
    "def select_features_null_imp(\n",
    "    version: str,\n",
    "    df: pd.DataFrame,\n",
    "    n_splits: int = 2\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Select features based on null importances.\n",
    "    \"\"\"\n",
    "    features_all = np.array(\n",
    "        [i for i in df.columns if i not in [COL_ID, COL_DATE, COL_TIME, COL_TARGET]]\n",
    "    )\n",
    "    random.shuffle(features_all)\n",
    "    n = n_splits\n",
    "    part_size = len(features_all) // n\n",
    "    remainder = len(features_all) % n\n",
    "    indices = [(i + 1) * part_size + (1 if i < remainder else 0) for i in range(n)]\n",
    "    feature_sets = [part.tolist() for part in np.array_split(features_all, indices[:-1])]\n",
    "\n",
    "    model_name = f\"lgb_version_{version}_nullimp\"\n",
    "\n",
    "    params_lgb = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'colsample_bynode': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'extra_trees': True,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 10,\n",
    "        'metric': 'auc',\n",
    "        'n_estimators': 4000,\n",
    "        'num_leaves': 64,\n",
    "        'objective': 'binary',\n",
    "        'random_state': 42,\n",
    "        'reg_alpha': 10,\n",
    "        'reg_lambda': 10,\n",
    "        \"device\": \"gpu\",\n",
    "        'verbose': -1,\n",
    "        \"max_bin\": 150,\n",
    "    }\n",
    "    imps = []\n",
    "    imps_null = []\n",
    "    model = LGBM(\n",
    "        params_lgb,\n",
    "        early_stopping_rounds=50,\n",
    "        test_size=0.01,\n",
    "        shuffle=True\n",
    "    )\n",
    "    for i, features in tqdm(enumerate(feature_sets), total=len(feature_sets)):\n",
    "        name = f\"{model_name}_full_{i}\"\n",
    "        print(f\"Number of features {len(features)}\")\n",
    "        pipeline = FullPipeline(\n",
    "            Pipeline(steps=[('model', model)]),\n",
    "            run_name=\"full\",\n",
    "            name=name,\n",
    "            load_model=False,\n",
    "            features=features\n",
    "        )\n",
    "        df_sample = df.sample(frac=0.5, random_state=i)\n",
    "        pipeline.fit(df_sample, verbose=True)\n",
    "        imp_df = pipeline.model[\"model\"].get_feature_importances()\n",
    "        imp_i_df = imp_df[[\"imp\"]]\n",
    "        imps.append(imp_i_df)\n",
    "\n",
    "        imp_null_i_df = get_null_imp(\n",
    "            df_sample,\n",
    "            features,\n",
    "            f\"{model_name}_full_{i}\",\n",
    "            params_lgb,\n",
    "            n=10\n",
    "        )\n",
    "        imps_null.append(imp_null_i_df)\n",
    "\n",
    "    imp_df = pd.concat(imps, axis=0)\n",
    "    imp_null_df = pd.concat(imps_null, axis=0)\n",
    "\n",
    "    imp_df[\"imp_null_75\"] = imp_null_df.quantile(0.75, axis=1)\n",
    "    imp_df[\"imp_final\"] = imp_df[\"imp\"] / (imp_df[\"imp_null_75\"] + 0.01)\n",
    "    imp_df.sort_values(\"imp_final\", ascending=False, inplace=True)\n",
    "    features_selected = imp_df[(imp_df[\"imp_final\"] > 1) & (imp_df[\"imp\"] > 1)].index.to_list()\n",
    "\n",
    "    imp_df.to_csv(f\"{base_path}/analysis/imp_null_{version}.csv\")\n",
    "\n",
    "    return features_selected\n",
    "\n",
    "\n",
    "def select_features_adv(\n",
    "    version: str,\n",
    "    df: pd.DataFrame,\n",
    "    features: list\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Select features based on adversarial validation.\n",
    "    \"\"\"\n",
    "    df[\"covid\"] = 0\n",
    "    df.loc[df[\"WEEK_NUM\"] >= 65, \"covid\"] = 1\n",
    "\n",
    "    df_train, df_valid = train_test_split(df, random_state=42)\n",
    "\n",
    "    params_lgb = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        \"n_estimators\": 20,\n",
    "        'random_state': 42,\n",
    "        \"device\": \"gpu\",\n",
    "        'verbose': -1,\n",
    "    }\n",
    "    model = LGBM(\n",
    "        params_lgb,\n",
    "        early_stopping_rounds=200,\n",
    "        test_size=0.01,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    print(f\"Number of features: {len(features)}\")\n",
    "    res_df = pd.DataFrame(index=features, columns=[\"score\"])\n",
    "\n",
    "    for f in tqdm(features):\n",
    "        pipeline = FullPipeline(\n",
    "            Pipeline(steps=[('model', model)]),\n",
    "            run_name=\"adv\",\n",
    "            name=\"test\",\n",
    "            load_model=False,\n",
    "            features=[f],\n",
    "            target_col=\"covid\"\n",
    "        )\n",
    "        try:\n",
    "            pipeline.fit(df_train)\n",
    "        except:\n",
    "            continue\n",
    "        preds = pipeline.predict(df_valid)\n",
    "        score = roc_auc_score(df_valid[\"covid\"], preds)\n",
    "        res_df.loc[f, \"score\"] = score\n",
    "\n",
    "    res_df.to_csv(f\"{base_path}/analysis/adv_val_features_{version}.csv\")\n",
    "    features_stable = res_df.loc[res_df[\"score\"] < 0.65].index.to_list()\n",
    "    return features_stable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Custom Data Processor and Feature Engineering\n",
    "\n",
    "* Custom data processor handles both the cleaning and advanced feature engineering. \n",
    "* Add rolling averages, standard deviations, and market-level statistics using Polars for fast computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    Custom data processor for feature engineering and transformation.\n",
    "    \n",
    "    This class includes methods for adding rolling differences, standard deviations, and market averages.\n",
    "    \"\"\"\n",
    "    PATH = os.path.join(PATH_MODELS, \"data_processors\")\n",
    "\n",
    "    COLS_FEATURES_INIT = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "\n",
    "    COLS_FEATURES_CORR = [\n",
    "        'feature_06',\n",
    "        'feature_04',\n",
    "        'feature_07',\n",
    "        'feature_36',\n",
    "        'feature_60',\n",
    "        'feature_45',\n",
    "        'feature_56',\n",
    "        'feature_05',\n",
    "        'feature_51',\n",
    "        'feature_19',\n",
    "        'feature_66',\n",
    "        'feature_59',\n",
    "        'feature_54',\n",
    "        'feature_70',\n",
    "        'feature_71', \n",
    "        'feature_72',\n",
    "    ]\n",
    "    COLS_FEATURES_CAT = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "\n",
    "    T = 1000\n",
    "\n",
    "    def __init__(self, name: str, skip_days: int = None, transformer: PolarsTransformer | None = None):\n",
    "        self.name = name\n",
    "        self.skip_days = skip_days\n",
    "        self.transformer = transformer\n",
    "\n",
    "        self.features = list(self.COLS_FEATURES_INIT)\n",
    "        self.features += [f\"{i}_diff_rolling_avg_{self.T}\" for i in self.COLS_FEATURES_CORR]\n",
    "        self.features += [f\"{i}_rolling_std_{self.T}\" for i in self.COLS_FEATURES_CORR]\n",
    "        self.features += [f\"{i}_avg_per_date_time\" for i in self.COLS_FEATURES_CORR]\n",
    "        self.features += [\"feature_time_id\"]\n",
    "        self.features = [i for i in self.features if i not in self.COLS_FEATURES_CAT]\n",
    "\n",
    "        utils.create_folder(self.PATH)\n",
    "\n",
    "    def get_train_data(self) -> pl.DataFrame:\n",
    "        df = self._load_data().collect()\n",
    "\n",
    "        df = df.with_columns(\n",
    "            (\n",
    "                pl.col(\"responder_8\") + pl.col(\"responder_8\").shift(-4).over(\"symbol_id\")\n",
    "            ).fill_null(0.0).alias(\"responder_9\"),\n",
    "            (\n",
    "                pl.col(\"responder_6\")\n",
    "                + pl.col(\"responder_6\").shift(-20).over(\"symbol_id\")\n",
    "                + pl.col(\"responder_6\").shift(-40).over(\"symbol_id\")\n",
    "            ).fill_null(0.0).alias(\"responder_10\"),\n",
    "        )\n",
    "\n",
    "        df = self._add_features(df)\n",
    "\n",
    "        if self.transformer is not None:\n",
    "            self.transformer.set_features(self.features)\n",
    "            df = self.transformer.fit_transform(df)\n",
    "\n",
    "        self._save()\n",
    "        return df\n",
    "\n",
    "    def process_test_data(self, df: pl.DataFrame, fast: bool = False, date_id: int = 0, time_id: int = 0, symbols: list = None) -> pl.DataFrame:\n",
    "        df = self._add_features(df, fast=fast, date_id=date_id, time_id=time_id, symbols=symbols)\n",
    "        if self.transformer is not None:\n",
    "            df = self.transformer.transform(df, refit=True)\n",
    "        return df\n",
    "\n",
    "    def _save(self):\n",
    "        joblib.dump(self, f\"{self.PATH}/{self.name}.joblib\")\n",
    "\n",
    "    def load(self):\n",
    "        return joblib.load(f\"{self.PATH}/{self.name}.joblib\")\n",
    "\n",
    "    def _load_data(self) -> pl.DataFrame:\n",
    "        df = pl.scan_parquet(f'{PATH_DATA}/train.parquet')\n",
    "        df = df.drop(\"partition_id\")\n",
    "        if self.skip_days is not None:\n",
    "            df = df.filter(pl.col(\"date_id\") >= self.skip_days)\n",
    "        return df\n",
    "\n",
    "    def _add_features(self, df: pl.DataFrame, fast: bool = False, date_id: int | None = None, time_id: int | None = None, symbols: list = None) -> pl.DataFrame:\n",
    "        df = self._get_window_average_std(df, self.COLS_FEATURES_CORR, n=self.T, fast=fast, date_id=date_id, time_id=time_id, symbols=symbols)\n",
    "        df = self._get_market_average(df, self.COLS_FEATURES_CORR, fast=fast)\n",
    "\n",
    "        df = df.with_columns(pl.col(\"time_id\").alias(\"feature_time_id\"))\n",
    "        return df\n",
    "\n",
    "    def _get_window_average_std(self, df: pl.DataFrame, cols: list, n: int = 1000, fast: bool = False, date_id: int | None = None, time_id: int | None = None, symbols: list = None) -> pl.DataFrame:\n",
    "        if not fast:\n",
    "            df = df.with_columns([\n",
    "                pl.col(col).rolling_mean(window_size=n).over([\"symbol_id\"]).alias(f\"{col}_rolling_avg_{n}\")\n",
    "                for col in cols\n",
    "            ] + [\n",
    "                pl.col(col).rolling_std(window_size=n).over([\"symbol_id\"]).alias(f\"{col}_rolling_std_{n}\")\n",
    "                for col in cols\n",
    "            ])\n",
    "        else:\n",
    "            df = df.group_by(\"symbol_id\").agg([\n",
    "                pl.col(col).mean().alias(f\"{col}_rolling_avg_{n}\")\n",
    "                for col in cols\n",
    "            ] + [\n",
    "                pl.col(col).std().alias(f\"{col}_rolling_std_{n}\")\n",
    "                for col in cols\n",
    "            ] + [\n",
    "                pl.col(col).last().alias(col)\n",
    "                for col in self.COLS_FEATURES_INIT + [\"row_id\", \"weight\", \"is_scored\"]\n",
    "            ]).filter(pl.col(\"symbol_id\").is_in(symbols))\n",
    "            df = df.with_columns(\n",
    "                pl.lit(date_id).cast(pl.Int16).alias(\"date_id\"),\n",
    "                pl.lit(time_id).cast(pl.Int16).alias(\"time_id\")\n",
    "            )\n",
    "\n",
    "        df = df.with_columns([\n",
    "            (pl.col(col) - pl.col(f\"{col}_rolling_avg_{n}\")).alias(f\"{col}_diff_rolling_avg_{n}\")\n",
    "            for col in cols\n",
    "        ])\n",
    "        df = df.drop([f\"{col}_rolling_avg_{n}\" for col in cols])\n",
    "        return df\n",
    "\n",
    "    def _get_market_average(self, df: pl.DataFrame, cols: list, fast: bool = False) -> pl.DataFrame:\n",
    "        if not fast:\n",
    "            df = df.with_columns([\n",
    "                pl.col(col).mean().over([\"date_id\", \"time_id\"]).alias(f\"{col}_avg_per_date_time\")\n",
    "                for col in cols\n",
    "            ])\n",
    "        else:\n",
    "            df = df.with_columns([\n",
    "                pl.col(col).mean().alias(f\"{col}_avg_per_date_time\")\n",
    "                for col in cols\n",
    "            ])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Datasets Utility Functions\n",
    "\n",
    "* Helper functions to update and upload Kaggle datasets. \n",
    "* These utilities allow you to package the models and code and then update the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset(dataset_id: str, source_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Updates a Kaggle dataset with specific subfolders.\n",
    "    \"\"\"\n",
    "    original_source_path = Path(source_path)\n",
    "    temp_dir = Path(\"/tmp/kaggle_dataset_temp/models\")\n",
    "\n",
    "    if temp_dir.exists():\n",
    "        shutil.rmtree(temp_dir)\n",
    "    temp_dir.mkdir(parents=True)\n",
    "\n",
    "    for folder_name in [\"full\", \"data_processors\"]:\n",
    "        src = original_source_path / folder_name\n",
    "        dest = temp_dir / folder_name\n",
    "        if src.exists():\n",
    "            shutil.copytree(src, dest)\n",
    "        else:\n",
    "            print(f\"Warning: Folder '{src}' does not exist and won't be uploaded.\")\n",
    "\n",
    "    print(f\"Files in temp_dir ({temp_dir}):\")\n",
    "    for root, _, files in os.walk(temp_dir):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))\n",
    "\n",
    "    metadata = {\"id\": f\"{KAGGLE_USERNAME}/{dataset_id}\"}\n",
    "    metadata_path = temp_dir / 'dataset-metadata.json'\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    command = f\"kaggle datasets version -p '{temp_dir}' -m 'Updated dataset' -r zip\"\n",
    "    print(f\"Running command: {command}\")\n",
    "    os.system(command)\n",
    "\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "\n",
    "def upload_code(dataset_id: str, source_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Uploads a Python package to a Kaggle dataset.\n",
    "    \"\"\"\n",
    "    os.chdir(base_path)\n",
    "    run_shell_command(\"python setup.py sdist bdist_wheel\")\n",
    "\n",
    "    original_source_path = Path(source_path)\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    shutil.copy(original_source_path, temp_dir)\n",
    "    source_path = Path(temp_dir)\n",
    "\n",
    "    metadata = {\"id\": f\"{KAGGLE_USERNAME}/{dataset_id}\"}\n",
    "    metadata_path = source_path / 'dataset-metadata.json'\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    run_shell_command(f\"kaggle datasets version -p '{source_path}' -m 'Updated dataset'\")\n",
    "\n",
    "    os.remove(metadata_path)\n",
    "    shutil.rmtree(temp_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Project Environment, Evaluation, Logging\n",
    "\n",
    "* This section includes functions to set up the project environment \n",
    "    * loading environment variables, configuring Kaggle API and Weights & Biases, \n",
    "    * and a custom tracker class for experiment logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment(track: bool = False):\n",
    "    \"\"\"\n",
    "    Set up project environment.\n",
    "    \"\"\"\n",
    "    print(\"Loading environment variables from .env file...\")\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "    print(\"Setting up Kaggle API credentials...\")\n",
    "    run_shell_command(\"mkdir -p ~/.kaggle\")\n",
    "    run_shell_command(f\"cp '{base_path_data}/kaggle.json' ~/.kaggle/\")\n",
    "    run_shell_command(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
    "\n",
    "    if track:\n",
    "        print(\"Setting up Weights & Biases...\")\n",
    "        import wandb\n",
    "        wandb.login(key=os.environ.get('WANDB_TOKEN'))\n",
    "\n",
    "    print(\"Environment setup complete.\")\n",
    "\n",
    "\n",
    "class WandbTracker:\n",
    "    \"\"\"\n",
    "    Custom class for tracking experiments using WandB.\n",
    "    \"\"\"\n",
    "    def __init__(self, run_name: str, params: dict, category: str, comment: str) -> None:\n",
    "        self.run_name = run_name\n",
    "        self.params = params\n",
    "        self.category = category\n",
    "        self.comment = comment\n",
    "        self.api = wandb.Api()\n",
    "\n",
    "    def init_run(self, features: list) -> None:\n",
    "        config = self.params.copy()\n",
    "        config.update({\n",
    "            \"model\": \"lgb\",\n",
    "            \"category\": self.category,\n",
    "            \"comment\": self.comment,\n",
    "            \"n_features\": len(features)\n",
    "        })\n",
    "        wandb.init(\n",
    "            project=WANDB_PROJECT,\n",
    "            name=self.run_name,\n",
    "            config=config,\n",
    "            dir=base_path,\n",
    "            save_code=True\n",
    "        )\n",
    "        self.save_features(features)\n",
    "        print(f\"Running {self.run_name} model.\")\n",
    "        print(self.comment)\n",
    "\n",
    "    def save_features(self, features: list) -> None:\n",
    "        feature_file_path = \"features.txt\"\n",
    "        with open(feature_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            for feature in features:\n",
    "                file.write(f\"{feature}\\n\")\n",
    "        artifact = wandb.Artifact(name=f\"{self.run_name}-feature-list\", type=\"dataset\")\n",
    "        artifact.add_file(feature_file_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "\n",
    "    def save_data(self, df: pd.DataFrame, name: str) -> None:\n",
    "        tab = wandb.Table(columns=list(df.columns), data=df.values.tolist())\n",
    "        wandb.log({name: tab})\n",
    "\n",
    "    def alert(self, text: str) -> None:\n",
    "        wandb.alert(\n",
    "            title=f'Run {self.run_name} finished.',\n",
    "            text=text,\n",
    "            level=wandb.AlertLevel.INFO\n",
    "        )\n",
    "\n",
    "    def log_metrics(self, metrics: dict) -> None:\n",
    "        wandb.log(metrics)\n",
    "\n",
    "    def update_summary(self, run_id: str, summary_params: dict) -> None:\n",
    "        run = self.api.run(f\"eivolkova3/kaggle_home_credit/{run_id}\")\n",
    "        for key, val in summary_params.items():\n",
    "            run.summary[key] = val\n",
    "        run.summary.update()\n",
    "\n",
    "    def update_settings(self, run_id: str, settings_params: dict) -> None:\n",
    "        run = self.api.run(f\"eivolkova3/kaggle_home_credit/{run_id}\")\n",
    "        for key, val in settings_params.items():\n",
    "            run.settings[key] = val\n",
    "        run.update()\n",
    "\n",
    "    def finish(self) -> None:\n",
    "        wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
